%!TEX root = ../memoria.tex

\chapter{Conclusión}

La localización en interiores es sin duda uno de los problemas más importantes a resolver en el último tiempo, ya que, así como GPS es la tecnología de facto para posicionar en zonas exteriores, es necesario un framework o sistema global de posicionamiento en interiores, con precisión y estimación de error definidas y estandarizadas. Esto es un problema para los experimentadores, ya que las tecnologías actuales capaces de determinar posición son aún demasiado precarias por una parte y también complejas en su implementación.

Ante estas eventualidades, muchos investigadores han tratado de sobrellevar los problemas relativos al posicionamiento en interiores mediante técnicas que puedan minimizar el error debido a los constantes cambios en la organización de los recintos, ya que este es sin duda el mayor problema, el cambio espacial constante en interiores, lo cual repercute negativamente en todos los métodos y sistemas desarrollados, los cuales deben lidiar con estos cambios, y utilizar métodos para atenuar este ruido.

Para mejorar la exactitud, muchos acercamientos se han presentado, especialmente en el área de redes inalámbricas, ya que su implementación es relativamente fácil, además es posible establecer muchos marcos matemáticos de trabajo que dan muchas posibilidades de trabajar con ondas electromagnéticas. Para ello, se han desarrollado técnicas matemáticas con el fin de mejorar la precisión y disminuir el error, entre ellas algunas basadas en estadísticas, métodos de análisis de señales, comportamiento de las ondas electromagnéticas, métodos deterministas, entre otros.

Como el fin es manejar adecuadamente este ruido inherente que ocurre en interiores, es necesario utilizar técnicas capaces de aprender y que no solo se basen en ciertos comportamientos específicos de un determinado momento, ya que un recinto interior puede cambiar constantemente, ya sea por cambios en infraestructura, tránsito de personas, entre otros. Es por ello que en el presente trabajo se ha decidido utilizar métodos de máquinas de aprendizaje, ya que estos permiten aprender a partir de un grupo de ejemplos, los cuales en este caso pueden ser obtenidos a partir de varios días distintos, con el fin de tener un amplio rango de casos posibles, para que luego el algoritmo pueda generar patrones temporales y espaciales, y así mejorar la exactitud del posicionamiento.

Para el desarrollo de la experimentación se utilizan ondas Bluetooth mediante dispositivos Beacons, para medir que tan buenos resultados aportan a la investigación, además de los ya mencionados métodos de aprendizaje automático. Lo primero a tener en cuenta, es que como se demuestra en la propuesta de solución, las señales Bluetooth y en general cualquier onda electromagnética se ve afectada profundamente por cualquier objeto que se interponga, en este caso se ha probado particularmente con una persona, y como es bien sabido, gran parte del cuerpo humano es agua, con lo cual la señal percibida en el receptor decae, por lo que esto afecta negativamente a los algoritmos y métodos matemáticos, ya que la información porta ruido e interferencia.

Con respecto las mediciones obtenidas, es claro que los datos recolectados presentan estructuras no lineales, pero con correlaciones lineales en sus vecindarios, por lo que en general, los mejores algoritmos de máquinas de aprendizaje son aquellos capaces de reconocer estas estructuras. En este trabajo particularmente se prueban muchos métodos de máquinas de aprendizaje, pero los mejores resultan ser KNN, SVM con Kernel Gaussiano y Redes Neuronales, por lo que se menciona anteriormente, es decir, estos son capaces de reconocer estructuras no lineales. 

A partir de la experimentación en la fase online, se determina que el mejor algoritmo para el posicionamiento corresponde a Redes Neuronales artificiales, mediante un análisis de CDF, Boxplot y medidas de error medio como RMSE. Además, se debe considerar el uso de Principal components analysis, el cual permite eliminar la correlación lineal y también disminuir la dimensionalidad de los datos.

El mejor resultado para el método dinámico ( en movimiento) corresponde a KNN con PCA, con un error medio de 6.6812 metros, seguido de NN con PCA y SVM  con PCA. Por otra parte, para el método estático, los resultados cambian y los mejores valores se obtienen en NN con PCA con 3.9341 metros de error, seguido de KNN con PCA y finalmente SVM con PCA.

Según el estudio, el mejor algoritmo, es decir, el más estable resulta ser KNN, ya que se comporta similar tanto en el método dinámico como estático. Luego redes neuronales presentan los mejores valores de error en términos generales, pero es mucho más inestable, y sus rangos de dispersión más altos, por lo que, aunque puede presentar menores valores de error, esto no siempre ocurre, y en general oscila entre valores bajos y medios de error.

Con respecto al uso de PCA, es claro que utilizarlo es definitivamente la mejor opción, sobre todo en algoritmos como KNN y SVM, debido a que reduce sustancialmente el tiempo de computo, y además mejora la precisión, disminuyendo el error presente en los algoritmos. A pesar de lo anterior, y de que PCA disminuye el error, al utilizarlo en redes neuronales se puede observar que su rango de dispersión aumenta significativamente, e incluso en el método estático presenta peores valores de error, por lo que para redes neuronales artificiales, aunque eventualmente pueda mejorar el tiempo de computo, es mejor no utilizar PCA, ya que  NN ya trae incorporado su propio método de disminuir la dimensionalidad al buscar patrones y tendencias locales, con lo cual no es necesario PCA en este último caso.

Con respecto al tiempo, PCA logra disminuir la complejidad computacional en 8.13\% para KNN, 53.09 \% para SVM y 24.08\% para NN. Con todo lo anterior, la mejor elección es redes neuronales artificiales siempre y cuando se esté hablando de error, por otra parte si se toma en consideración la estabilidad de los datos, es decir, su dispersión sobre las medidas de tendencia central, KNN es por lejos el ganador. SVM, es sin duda el peor de los tres, ya que no posee mejores valores de error o menor dispersión en sus datos de error.

Los análisis indican entonces que utilizar Bluetooth con técnicas de máquinas de aprendizaje, pueden reducir el error a unos pocos metros, particularmente el mejor valor encontrado lo obtienen las redes neuronales artificiales con 3.9341 metros, lo cual es relativamente alto si se considera un posicionamiento en tiempo real, preciso y sin grandes errores, como es de esperar. Esto indica entonces que el sistema presentado en este trabajo puede ser la base para estimar la posición asociada a una región o zona geográfica de un recinto interior, pero no para determinar efectivamente la localización en tiempo real.

Claramente no se logra el objetivo de obtener una precisión de unos pocos centímetros como logra hacerlo GPS, sin embargo, este trabajo sirve como base para futuras investigaciones, ya que quedan muchas incógnitas abiertas, principalmente análisis de la distribución y densidad del posicionamiento de los Beacons Bluetooth, es decir, estudios sobre cuantos Beacons utilizar sobre una determinada región. Por otra parte, el análisis de la grilla, ya que en este caso se utiliza una de $ 4\times 4$ metros, lo cual es muy grande, por lo que los errores en la clasificación aumentan significativamente al errar en clasificar; entonces sería razonable analizar qué tamaño de grilla produce los mejores resultados. Por otro lado, sería interesante analizar que ocurre al utilizar las técnicas presentadas en este trabajo, en conjunto con otros métodos como puede ser localización por magnetismo, fusión de sensores inerciales, o las mismas señales WiFi en conjunto con señales Bluetooth.

Con respecto a el modo de recolección de fingerprints, esto es aún un problema para esta técnica, ya que en espacios reducidos, en la fase offline la recolección es mucho más rápida, sobre todo con grillas de tamaño grande, sin embargo, si el recinto contiene muchos puntos de referencia, la recolección es lenta y requiere mucho esfuerzo, ya que no solo basta con la recolección inicial de fingerprints, sino que cada cierto tiempo se debe actualizar los modelos, debido al cambio espacial en la disposición interior de los objetos. Esto es sin duda uno de los problemas más grandes de Fingerprint y que debe ser resuelto para lograr posicionamiento con buena precisión. Una posible solución es tener dispositivos receptores que actualicen la base de datos en tiempo real, pero ahí el problema es reentrenar los algoritmos de clasificación sobre la marcha, lo cual es muy complejo.

A pesar de que este trabajo solo se utilizan algoritmos de clasificación supervisados, otra alternativa para la localización a nivel de región es utilizar clasificadores no supervisados, es decir, reconocimiento de patrones sin necesidad de indicar la posición, esto reduce considerablemente el esfuerzo para la recolección de fingerprint, ya que en la fase de entrenamiento no es necesario pasar al algoritmo la etiqueta de cada punto, es decir, la posición, sino que es el mismo algoritmo el que se encargaría de reconocer patrones en las señales, sin importar el ruido inherente, por lo que en este contexto, se puede localizar a nivel de regiones, es decir, habitaciones o niveles. Si bien esto no es tan preciso, en conjunto con algoritmos de clasificación supervisados puede ayudar a dar pistas a los algoritmos de machine learning, para así obtener mejores resultados.


A partir de los estudios realizados, se puede determinar que las maquinas de aprendizaje en conjunto con las señales Bluetooth Low Energy pueden ser un punto de partida para mejorar la precisión y disminuir el error del posicionamiento en interiores, en particular el Deep Learning, con el framework Tensorflow, el cual puede ser portado fácilmente a cualquier dispositivo móvil, con lo que es factible utilizar, además de ser sumamente rápido una vez que las redes están entrenadas. Como conclusión final, se debe notar que en este caso solo se utiliza un lugar de experimentación, en particular, un estacionamiento, con lo que estos modelos entrenados no funcionarían en otros recintos. Este es el mayor problema del posicionamiento en interiores, lograr un modelo estándar, que funcione relativamente bien en gran parte de los escenarios y no dependa específicamente del lugar de experimentación. Por el momento esto no es posible, y sigue en constante investigación, ya que aun se deben resolver muchas preguntas que están abiertas para lograr realmente un sistema fiable y preciso que pueda localizar en interiores.