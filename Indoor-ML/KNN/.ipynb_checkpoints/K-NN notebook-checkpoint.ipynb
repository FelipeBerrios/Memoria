{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdf_raw = pd.read_csv(\"../IndoorFingerprint.csv\").drop(\"Y\", axis=1)\n",
    "Ydf_raw = pd.read_csv(\"../IndoorFingerprint.csv\").drop(\"X\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinal_numbers = 4;\n",
    "atribute_numbers = Xdf_raw.shape[1]-1\n",
    "\n",
    "# Valores para el dataset que predice X\n",
    "Xtrx, Xtex, ytrx, ytex = train_test_split(\n",
    "Xdf_raw.iloc[:, 1:], Xdf_raw[\"X\"], test_size=0.2, random_state=0)\n",
    "train_size = len(Xtrx)\n",
    "test_size = len(Xtex)\n",
    "\n",
    "# Valores para el dataset que predice Y\n",
    "Xtry, Xtey, ytry, ytey = train_test_split(\n",
    "Ydf_raw.iloc[:, 1:], Ydf_raw[\"Y\"], test_size=0.2, random_state=0)\n",
    "\n",
    "# Se normalizan los datos para ambos\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Xtrx.iloc[:, 4:atribute_numbers] = scaler.fit_transform(Xtrx.iloc[:, 4:atribute_numbers])\n",
    "Xtex.iloc[:, 4:atribute_numbers] = scaler.transform(Xtex.iloc[:, 4:atribute_numbers])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Xtry.iloc[:, 4:atribute_numbers] = scaler.fit_transform(Xtry.iloc[:, 4:atribute_numbers])\n",
    "Xtey.iloc[:, 4:atribute_numbers] = scaler.transform(Xtey.iloc[:, 4:atribute_numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se generan los parametros para el algoritmo KNN\n",
    "k = 3\n",
    "batch_size=6\n",
    "class_number = ytrx.unique().size\n",
    "\n",
    "ytrx_dummy = pd.get_dummies(ytrx)\n",
    "ytex_dummy = pd.get_dummies(ytex)\n",
    "\n",
    "# Se convierten valores a Tensores \n",
    "\n",
    "Xtrx = np.array(Xtrx,dtype='float32')\n",
    "Xtex = np.array(Xtex,dtype='float32')\n",
    "ytrx_dummy = np.array(ytrx_dummy,dtype='float32')\n",
    "ytex_dummy = np.array(ytex_dummy,dtype='float32')\n",
    "\n",
    "x_data_train_x = tf.placeholder(shape=[None, atribute_numbers], dtype=tf.float32)\n",
    "x_data_test_x = tf.placeholder(shape=[None, atribute_numbers], dtype=tf.float32)\n",
    "y_target_train_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\n",
    "y_target_test_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\n",
    "\n",
    "biases = tf.Variable(tf.zeros([200]), name=\"biases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se utiliza distancia L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(x_data_train_x, tf.expand_dims(x_data_test_x,1))), reduction_indices=1))\n",
    "distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train_x, tf.expand_dims(x_data_test_x,1))), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9583333333333339\n"
     ]
    }
   ],
   "source": [
    "# Get min distance index (Nearest neighbor)\n",
    "top_k_xvals, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n",
    "prediction_indices = tf.gather(y_target_train_x, top_k_indices)\n",
    "\n",
    "# Predict the mode category\n",
    "count_of_predictions = tf.reduce_sum(prediction_indices, axis=1)\n",
    "prediction = tf.argmax(count_of_predictions, axis=1, name=\"O\")\n",
    "\n",
    "# Calculate how many loops over training data\n",
    "num_loops = int(np.ceil(len(Xtex)/batch_size))\n",
    "\n",
    "test_output = []\n",
    "actual_vals = []\n",
    "\n",
    "#initialize of all variables\n",
    "saver = tf.train.Saver()\n",
    "init_op=tf.global_variables_initializer()\n",
    "\n",
    "#start of tensor session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(num_loops):\n",
    "        min_index = i*batch_size\n",
    "        max_index = min((i+1)*batch_size,len(Xtrx))\n",
    "        x_batch = Xtex[min_index:max_index]\n",
    "        y_batch = ytex_dummy[min_index:max_index]\n",
    "        predictions = sess.run(prediction, feed_dict={x_data_train_x: Xtrx, x_data_test_x: x_batch,\n",
    "                                             y_target_train_x: ytrx_dummy, y_target_test_x: y_batch})\n",
    "        test_output.extend(predictions)\n",
    "        actual_vals.extend(np.argmax(y_batch, axis=1))\n",
    "\n",
    "    accuracy = sum([1./test_size for i in range(test_size) if test_output[i]==actual_vals[i]])\n",
    "    print('Accuracy on test set: ' + str(accuracy))\n",
    "    \n",
    "    \n",
    "    # Guardar grafos y variables\n",
    "    tf.train.write_graph(sess.graph_def, './files_knn', 'knn.pbtxt',as_text = True)\n",
    "    saver.save(sess,save_path = \"./files_knn/knn.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.tools import freeze_graph\\nfrom tensorflow.python.tools import optimize_for_inference_lib\\n\\nfreeze_graph.freeze_graph(input_graph = \"./files_knn/knn.pbtxt\",  input_saver = \"\",\\n             input_binary = False, input_checkpoint = \"./files_knn/knn.ckpt\", output_node_names = \"O\",\\n             restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\",\\n             output_graph = \"./files_knn/frozen_knn.pb\", clear_devices = True, initializer_nodes = \"\")\\n\\ninput_graph_def = tf.GraphDef()\\nwith tf.gfile.Open(output_frozen_graph_name, \"r\") as f:\\n    data = f.read()\\n    input_graph_def.ParseFromString(data)\\n\\noutput_graph_def = optimize_for_inference_lib.optimize_for_inference(\\n        input_graph_def,\\n        [\"input\"], \\n        [\"O\"],\\n        tf.float32.as_datatype_enum)\\n\\nf = tf.gfile.FastGFile(\"optimized_knn.pb\", \"w\")\\nf.write(output_graph_def.SerializeToString())'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph = \"./files_knn/knn.pbtxt\",  input_saver = \"\",\n",
    "             input_binary = False, input_checkpoint = \"./files_knn/knn.ckpt\", output_node_names = \"O\",\n",
    "             restore_op_name = \"save/restore_all\", filename_tensor_name = \"save/Const:0\",\n",
    "             output_graph = \"./files_knn/frozen_knn.pb\", clear_devices = True, initializer_nodes = \"\")\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(output_frozen_graph_name, \"r\") as f:\n",
    "    data = f.read()\n",
    "    input_graph_def.ParseFromString(data)\n",
    "\n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "        input_graph_def,\n",
    "        [\"input\"], \n",
    "        [\"O\"],\n",
    "        tf.float32.as_datatype_enum)\n",
    "\n",
    "f = tf.gfile.FastGFile(\"optimized_knn.pb\", \"w\")\n",
    "f.write(output_graph_def.SerializeToString())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#K-near\\nK=3 #how many neighbors\\nnearest_neighbors=tf.Variable(tf.zeros([K]))\\n\\nclass_number = y_train_x.unique().size\\n\\ny_train_x_dummy = pd.get_dummies(y_train_x)\\ny_test_x_dummy = pd.get_dummies(y_test_x)\\n\\n# Se convierten valores a Tensores \\n\\nX_train_x = np.array(X_train_x,dtype=\\'float32\\')\\nX_test_x = np.array(X_test_x,dtype=\\'float32\\')\\ny_train_x_dummy = np.array(y_train_x_dummy,dtype=\\'float32\\')\\ny_test_x_dummy = np.array(y_test_x_dummy,dtype=\\'float32\\')\\n\\nx_data_train_x = tf.placeholder(shape=[None, atribute_numbers], dtype=tf.float32)\\nx_data_test_x = tf.placeholder(shape=[atribute_numbers], dtype=tf.float32)\\ny_target_train_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\\ny_target_test_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\\n\\n#model\\ndistance = tf.negative(tf.reduce_sum(tf.abs(tf.subtract(x_data_train_x, x_data_test_x)),axis=1)) #L1\\n# the negitive above if so that top_k can get the lowest distance *_* its a really good hack i learned\\nvalues,indices=tf.nn.top_k(distance,k=K,sorted=False)\\n\\n#a normal list to save\\nnn = []\\nfor i in range(K):\\n    nn.append(tf.argmax(y_target_train_x[indices[i]], 0)) #taking the result indexes\\n\\n#saving list in tensor variable\\nnearest_neighbors=nn\\n# this will return the unique neighbors the count will return the most common\\'s index\\ny, idx, count = tf.unique_with_counts(nearest_neighbors)\\n\\npred = tf.slice(y, begin=[tf.argmax(count, 0)], size=tf.constant([1], dtype=tf.int64))[0]\\n# this is tricky count returns the number of repetation in each elements of y and then by begining from that and size begin 1\\n# it only returns that neighbors value : for example\\n# suppose a is array([11,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  4,  4,  4,  4]) so unique_with_counts of a will\\n#return y= (array([ 1,  2,  3,  4, 11]) count= array([3, 3, 2, 7, 1])) so argmax of count will be 3 which will be the\\n#index of 4 in y which is the hight number in a\\n\\n#setting accuracy as 0\\naccuracy=0\\n\\n#initialize of all variables\\ninit=tf.global_variables_initializer()\\n\\n#start of tensor session\\nwith tf.Session() as sess:\\n\\n    for i in range(X_test_x.shape[0]):\\n        #return the predicted value\\n        predicted_value=sess.run(pred,feed_dict={x_data_train_x:X_train_x,y_target_train_x:y_train_x_dummy,\\n                                                 x_data_test_x:X_test_x[i,:]})\\n\\n        print(\"Test\",i,\"Prediction\",predicted_value,\"True Class:\",np.argmax(y_test_x_dummy[i]))\\n\\n        if predicted_value == np.argmax(y_test_x_dummy[i]):\\n            # if the prediction is right then a double value of 1./200 is added 200 here is the number of test\\n                accuracy += 1. / len(X_test_x)\\n    writer = tf.summary.FileWriter(\\'./graphs\\',sess.graph)\\n    writer.close()\\n    # tensorboard --logdir=\"./graphs\" --port 6006 in command promt to see the graph at localhost:6006\\n    print(\"Calculation completed ! ! \")\\n    print(K,\"-th neighbors\\' Accuracy is:\",accuracy)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#K-near\n",
    "K=3 #how many neighbors\n",
    "nearest_neighbors=tf.Variable(tf.zeros([K]))\n",
    "\n",
    "class_number = y_train_x.unique().size\n",
    "\n",
    "y_train_x_dummy = pd.get_dummies(y_train_x)\n",
    "y_test_x_dummy = pd.get_dummies(y_test_x)\n",
    "\n",
    "# Se convierten valores a Tensores \n",
    "\n",
    "X_train_x = np.array(X_train_x,dtype='float32')\n",
    "X_test_x = np.array(X_test_x,dtype='float32')\n",
    "y_train_x_dummy = np.array(y_train_x_dummy,dtype='float32')\n",
    "y_test_x_dummy = np.array(y_test_x_dummy,dtype='float32')\n",
    "\n",
    "x_data_train_x = tf.placeholder(shape=[None, atribute_numbers], dtype=tf.float32)\n",
    "x_data_test_x = tf.placeholder(shape=[atribute_numbers], dtype=tf.float32)\n",
    "y_target_train_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\n",
    "y_target_test_x = tf.placeholder(shape=[None, class_number], dtype=tf.float32)\n",
    "\n",
    "#model\n",
    "distance = tf.negative(tf.reduce_sum(tf.abs(tf.subtract(x_data_train_x, x_data_test_x)),axis=1)) #L1\n",
    "# the negitive above if so that top_k can get the lowest distance *_* its a really good hack i learned\n",
    "values,indices=tf.nn.top_k(distance,k=K,sorted=False)\n",
    "\n",
    "#a normal list to save\n",
    "nn = []\n",
    "for i in range(K):\n",
    "    nn.append(tf.argmax(y_target_train_x[indices[i]], 0)) #taking the result indexes\n",
    "\n",
    "#saving list in tensor variable\n",
    "nearest_neighbors=nn\n",
    "# this will return the unique neighbors the count will return the most common's index\n",
    "y, idx, count = tf.unique_with_counts(nearest_neighbors)\n",
    "\n",
    "pred = tf.slice(y, begin=[tf.argmax(count, 0)], size=tf.constant([1], dtype=tf.int64))[0]\n",
    "# this is tricky count returns the number of repetation in each elements of y and then by begining from that and size begin 1\n",
    "# it only returns that neighbors value : for example\n",
    "# suppose a is array([11,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  4,  4,  4,  4]) so unique_with_counts of a will\n",
    "#return y= (array([ 1,  2,  3,  4, 11]) count= array([3, 3, 2, 7, 1])) so argmax of count will be 3 which will be the\n",
    "#index of 4 in y which is the hight number in a\n",
    "\n",
    "#setting accuracy as 0\n",
    "accuracy=0\n",
    "\n",
    "#initialize of all variables\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "#start of tensor session\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    for i in range(X_test_x.shape[0]):\n",
    "        #return the predicted value\n",
    "        predicted_value=sess.run(pred,feed_dict={x_data_train_x:X_train_x,y_target_train_x:y_train_x_dummy,\n",
    "                                                 x_data_test_x:X_test_x[i,:]})\n",
    "\n",
    "        print(\"Test\",i,\"Prediction\",predicted_value,\"True Class:\",np.argmax(y_test_x_dummy[i]))\n",
    "\n",
    "        if predicted_value == np.argmax(y_test_x_dummy[i]):\n",
    "            # if the prediction is right then a double value of 1./200 is added 200 here is the number of test\n",
    "                accuracy += 1. / len(X_test_x)\n",
    "    writer = tf.summary.FileWriter('./graphs',sess.graph)\n",
    "    writer.close()\n",
    "    # tensorboard --logdir=\"./graphs\" --port 6006 in command promt to see the graph at localhost:6006\n",
    "    print(\"Calculation completed ! ! \")\n",
    "    print(K,\"-th neighbors' Accuracy is:\",accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
